<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"> <title>Rainfall Camera &#8211; (Allen) Zhi Li</title> <meta name="description" content="Rainfall CameraContents1. Introduction2. Classifier3. Normal Rainfall Processing3.1 Model Description3.2 Model Efficiency4. Heavy Rainfall Processing5. Night Image Processing6. Validation7. Reference8. Misc8.1 Demo8.2 To-do List8.3 UpdatesIntroduction Fig.1 Flow Chart of Rainfall Camera Classifier Model Description: The model built for classifying rainfall images is SVM, which in general, seperate datapoints with hyperplanes. The reason why we build a relatively light model is for the sake of computational time. The simplest and robust way is what we seek for. Data Acquisition: To build such machine-learning model, we still need information to train it. With four categories we want to specify, 100 images inside each category are selected from the streaming videos. Image size to train is confined with (300,300). Information to support: With data, how can we translate image into useful information that we can feed into SVM? By considering the characteristics during night, rainy days, heavy rainfall and sunny days, I came up with five informative descriptions: contrast, brightness, sharpness, hue and saturation. Return: After implementing this classifier, we are able to get a assigned probability of each category for single image.Normal Rainfall ProcessingModel DescriptionFollow the pipeline, we emphisize on how to extract the rainfall intensity. In this method we describe, we feed the classified rainy image denoted as R into 4 times pretrained recurrent neuron network to get the original de-rained image O. By simple substracting and binary thresholding, we are able to get rainfall streaks S for analysis. But according to experiment, some images still quite messy under the condition that the moving trees and some hight pixel values give a false signal. In order to safeguard the following calculation process, we need to provide more accurate rainfall streaks. By achieving this, we decompose S with PCA and analyse the morphology of rain streaks etc. the shape of rain streak, the width of the rain streak, the orientation of the rain streak. With provided constraints, the output purified image will eventually put into Allamano algorithm. Fig.2 Pipeline of normal rainfall process1. RNN Fig.3 Overview of RNN model (Progressive Image Deraining Networks: A Better and Simpler Baseline) 2. Allamano Algorithm Fig.4 Example of delineated rain streaks Allamano Algorithm is used for evaluating the rainfall intensity, the philosophi behind is control volume approach to count rain drops inside the defined bounding box, and calculate rainfall terminal velocity etc.an event on 2018.12.08 demonstrates the accuracy of this series of images. Fig.5 Event 2018.12.12 at H2i, Singapore Model Efficiency Object Total Elapsed Time Average Elapsed Time per Image GPU_CPU Cores or Threads 2018.04.01 1.12 hours 1.30 seconds GPU 8 2018.12.08 0.45 hours 0.91 seconds GPU 8 2018.12.11 0.71 hours 1.03 seconds GPU 8 2018.12.12 1.15 hours 1.34 seconds GPU 8 Heavy Rainfall ProcessingSo far, we are limited by the data available to supervise a model towards the &quot;correct&quot; pathwill add once more data can be aquiredNight Image ProcessingSome modern techniques goes here.ValidationWe have three data sources to validate our camera accuracy, first are three radars located in the northern, eastern and western part of Singapore. Another sources are 83 rain gauges densely distributed in Singapore. To bear in mind, the nearest rain gauges is still 300 meters away, and radar averages surroundings by 700 meters by 700 meters median filter. These two biases indicate that none of the two are convincible, and no updates will be given before some in-site measurement is placed right with camera. Fig.6 Time Series Plot of One Event Fig.7 Cumulative Time Series Plot of One Event ReferenceR. Dongwei, Z. Wangmeng etc. (2019) Progressive Image Deraining Networks: A Better and Simpler BaselineR. Martin and M. Frank (2008.) Classification of Weather Situations on Single Color ImagesP. Allamano, A. Croci, and F. Laio1 (2015) Toward the camera rain gaugeMiscellaneousDemoIn the api folder, there is a simple demo classifying an image and extract the rainfall intensity with built Flask backendpython api.pya local server should be set up at port 8000, in your browser, enter in localhost:8000, then the interface will pop up as Fig.5 Snapshot of the local server To-do list [x] build dask task manager [x] add classifier [x] Flask server [ ] Host on cloud [ ] add regression model/convert to RGB image [ ] night image processing [ ] GUI [x] add visualization [ ] add computational time table [ ] GPU version(convert all dask array to torch array and hard code torch version SVM) [ ] Validation with radar and rain gaugesUpdates2019.4.24 Optimize codes to speed up.2019.4.22 Flask local server to classify image2019.4.19 add visualization.py2019.4.18 optimized code and retrained model2019.4.17 dask implementation2019.4.15 trained a classifier model"> <meta name="keywords" content="machine learning, deep learning, hydroinformatics, data scientist"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="allen.png"> <meta name="twitter:title" content="Rainfall Camera"> <meta name="twitter:description" content="Rainfall CameraContents1. Introduction2. Classifier3. Normal Rainfall Processing3.1 Model Description3.2 Model Efficiency4. Heavy Rainfall Processing5. Night Image Processing6. Validation7. Reference8. Misc8.1 Demo8.2 To-do List8.3 UpdatesIntroduction Fig.1 Flow Chart of Rainfall Camera Classifier Model Description: The model built for classifying rainfall images is SVM, which in general, seperate datapoints with hyperplanes. The reason why we build a relatively light model is for the sake of computational time. The simplest and robust way is what we seek for. Data Acquisition: To build such machine-learning model, we still need information to train it. With four categories we want to specify, 100 images inside each category are selected from the streaming videos. Image size to train is confined with (300,300). Information to support: With data, how can we translate image into useful information that we can feed into SVM? By considering the characteristics during night, rainy days, heavy rainfall and sunny days, I came up with five informative descriptions: contrast, brightness, sharpness, hue and saturation. Return: After implementing this classifier, we are able to get a assigned probability of each category for single image.Normal Rainfall ProcessingModel DescriptionFollow the pipeline, we emphisize on how to extract the rainfall intensity. In this method we describe, we feed the classified rainy image denoted as R into 4 times pretrained recurrent neuron network to get the original de-rained image O. By simple substracting and binary thresholding, we are able to get rainfall streaks S for analysis. But according to experiment, some images still quite messy under the condition that the moving trees and some hight pixel values give a false signal. In order to safeguard the following calculation process, we need to provide more accurate rainfall streaks. By achieving this, we decompose S with PCA and analyse the morphology of rain streaks etc. the shape of rain streak, the width of the rain streak, the orientation of the rain streak. With provided constraints, the output purified image will eventually put into Allamano algorithm. Fig.2 Pipeline of normal rainfall process1. RNN Fig.3 Overview of RNN model (Progressive Image Deraining Networks: A Better and Simpler Baseline) 2. Allamano Algorithm Fig.4 Example of delineated rain streaks Allamano Algorithm is used for evaluating the rainfall intensity, the philosophi behind is control volume approach to count rain drops inside the defined bounding box, and calculate rainfall terminal velocity etc.an event on 2018.12.08 demonstrates the accuracy of this series of images. Fig.5 Event 2018.12.12 at H2i, Singapore Model Efficiency Object Total Elapsed Time Average Elapsed Time per Image GPU_CPU Cores or Threads 2018.04.01 1.12 hours 1.30 seconds GPU 8 2018.12.08 0.45 hours 0.91 seconds GPU 8 2018.12.11 0.71 hours 1.03 seconds GPU 8 2018.12.12 1.15 hours 1.34 seconds GPU 8 Heavy Rainfall ProcessingSo far, we are limited by the data available to supervise a model towards the &quot;correct&quot; pathwill add once more data can be aquiredNight Image ProcessingSome modern techniques goes here.ValidationWe have three data sources to validate our camera accuracy, first are three radars located in the northern, eastern and western part of Singapore. Another sources are 83 rain gauges densely distributed in Singapore. To bear in mind, the nearest rain gauges is still 300 meters away, and radar averages surroundings by 700 meters by 700 meters median filter. These two biases indicate that none of the two are convincible, and no updates will be given before some in-site measurement is placed right with camera. Fig.6 Time Series Plot of One Event Fig.7 Cumulative Time Series Plot of One Event ReferenceR. Dongwei, Z. Wangmeng etc. (2019) Progressive Image Deraining Networks: A Better and Simpler BaselineR. Martin and M. Frank (2008.) Classification of Weather Situations on Single Color ImagesP. Allamano, A. Croci, and F. Laio1 (2015) Toward the camera rain gaugeMiscellaneousDemoIn the api folder, there is a simple demo classifying an image and extract the rainfall intensity with built Flask backendpython api.pya local server should be set up at port 8000, in your browser, enter in localhost:8000, then the interface will pop up as Fig.5 Snapshot of the local server To-do list [x] build dask task manager [x] add classifier [x] Flask server [ ] Host on cloud [ ] add regression model/convert to RGB image [ ] night image processing [ ] GUI [x] add visualization [ ] add computational time table [ ] GPU version(convert all dask array to torch array and hard code torch version SVM) [ ] Validation with radar and rain gaugesUpdates2019.4.24 Optimize codes to speed up.2019.4.22 Flask local server to classify image2019.4.19 add visualization.py2019.4.18 optimized code and retrained model2019.4.17 dask implementation2019.4.15 trained a classifier model"> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="Rainfall Camera"> <meta property="og:description" content="Rainfall CameraContents1. Introduction2. Classifier3. Normal Rainfall Processing3.1 Model Description3.2 Model Efficiency4. Heavy Rainfall Processing5. Night Image Processing6. Validation7. Reference8. Misc8.1 Demo8.2 To-do List8.3 UpdatesIntroduction Fig.1 Flow Chart of Rainfall Camera Classifier Model Description: The model built for classifying rainfall images is SVM, which in general, seperate datapoints with hyperplanes. The reason why we build a relatively light model is for the sake of computational time. The simplest and robust way is what we seek for. Data Acquisition: To build such machine-learning model, we still need information to train it. With four categories we want to specify, 100 images inside each category are selected from the streaming videos. Image size to train is confined with (300,300). Information to support: With data, how can we translate image into useful information that we can feed into SVM? By considering the characteristics during night, rainy days, heavy rainfall and sunny days, I came up with five informative descriptions: contrast, brightness, sharpness, hue and saturation. Return: After implementing this classifier, we are able to get a assigned probability of each category for single image.Normal Rainfall ProcessingModel DescriptionFollow the pipeline, we emphisize on how to extract the rainfall intensity. In this method we describe, we feed the classified rainy image denoted as R into 4 times pretrained recurrent neuron network to get the original de-rained image O. By simple substracting and binary thresholding, we are able to get rainfall streaks S for analysis. But according to experiment, some images still quite messy under the condition that the moving trees and some hight pixel values give a false signal. In order to safeguard the following calculation process, we need to provide more accurate rainfall streaks. By achieving this, we decompose S with PCA and analyse the morphology of rain streaks etc. the shape of rain streak, the width of the rain streak, the orientation of the rain streak. With provided constraints, the output purified image will eventually put into Allamano algorithm. Fig.2 Pipeline of normal rainfall process1. RNN Fig.3 Overview of RNN model (Progressive Image Deraining Networks: A Better and Simpler Baseline) 2. Allamano Algorithm Fig.4 Example of delineated rain streaks Allamano Algorithm is used for evaluating the rainfall intensity, the philosophi behind is control volume approach to count rain drops inside the defined bounding box, and calculate rainfall terminal velocity etc.an event on 2018.12.08 demonstrates the accuracy of this series of images. Fig.5 Event 2018.12.12 at H2i, Singapore Model Efficiency Object Total Elapsed Time Average Elapsed Time per Image GPU_CPU Cores or Threads 2018.04.01 1.12 hours 1.30 seconds GPU 8 2018.12.08 0.45 hours 0.91 seconds GPU 8 2018.12.11 0.71 hours 1.03 seconds GPU 8 2018.12.12 1.15 hours 1.34 seconds GPU 8 Heavy Rainfall ProcessingSo far, we are limited by the data available to supervise a model towards the &quot;correct&quot; pathwill add once more data can be aquiredNight Image ProcessingSome modern techniques goes here.ValidationWe have three data sources to validate our camera accuracy, first are three radars located in the northern, eastern and western part of Singapore. Another sources are 83 rain gauges densely distributed in Singapore. To bear in mind, the nearest rain gauges is still 300 meters away, and radar averages surroundings by 700 meters by 700 meters median filter. These two biases indicate that none of the two are convincible, and no updates will be given before some in-site measurement is placed right with camera. Fig.6 Time Series Plot of One Event Fig.7 Cumulative Time Series Plot of One Event ReferenceR. Dongwei, Z. Wangmeng etc. (2019) Progressive Image Deraining Networks: A Better and Simpler BaselineR. Martin and M. Frank (2008.) Classification of Weather Situations on Single Color ImagesP. Allamano, A. Croci, and F. Laio1 (2015) Toward the camera rain gaugeMiscellaneousDemoIn the api folder, there is a simple demo classifying an image and extract the rainfall intensity with built Flask backendpython api.pya local server should be set up at port 8000, in your browser, enter in localhost:8000, then the interface will pop up as Fig.5 Snapshot of the local server To-do list [x] build dask task manager [x] add classifier [x] Flask server [ ] Host on cloud [ ] add regression model/convert to RGB image [ ] night image processing [ ] GUI [x] add visualization [ ] add computational time table [ ] GPU version(convert all dask array to torch array and hard code torch version SVM) [ ] Validation with radar and rain gaugesUpdates2019.4.24 Optimize codes to speed up.2019.4.22 Flask local server to classify image2019.4.19 add visualization.py2019.4.18 optimized code and retrained model2019.4.17 dask implementation2019.4.15 trained a classifier model"> <meta property="og:url" content="http://127.0.0.1:4000//post-camera/"> <meta property="og:site_name" content="(Allen) Zhi Li"> <meta property="og:image" content="http://127.0.0.1:4000//images/allen.png"> <link rel="canonical" href="http://127.0.0.1:4000//post-camera/"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- Feed --> <link type="application/atom+xml" rel="alternate" href="http://127.0.0.1:4000//feed.xml" title="" /> <!-- Favicons --> <link rel="shortcut icon" type="image/png" href="http://127.0.0.1:4000//favicon.png" /> <link rel="shortcut icon" href="http://127.0.0.1:4000//favicon.ico" /> <!-- CSS --> <link rel="stylesheet" type="text/css" href="http://127.0.0.1:4000//assets/css/main.css"> <!-- Left Block Image for Posts --> <style type="text/css"> #posts.inner-post-page .block-left {background: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url(http://127.0.0.1:4000//images/unsplash-gallery-image-3.jpg) no-repeat;background-size: cover;} </style> <!-- Left Block Images for Home and Pages --> <style type="text/css"> #posts .block-left {background: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url(http://127.0.0.1:4000//images/unsplash-image-10.jpg) no-repeat;background-size: cover, cover;} .block-left {background: linear-gradient(rgba(44,45,51,0.9), rgba(44,45,51,0.9)), url(http://127.0.0.1:4000//images/photo.jpg) no-repeat;background-size: cover;} </style> </head> <body id="posts" > <a href="http://127.0.0.1:4000/" class="logo"><img src="http://127.0.0.1:4000//images/allen.png"></a> <div class="post-block"> <!-- <div class="share-buttons"> <a href="https://twitter.com/intent/tweet?text=http://127.0.0.1:4000//post-camera/" class="btn btn_twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> <a href="https://www.facebook.com/sharer/sharer.php?u=http://127.0.0.1:4000//post-camera/" class="btn btn_facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a> <a href="https://plus.google.com/share?url=http://127.0.0.1:4000//post-camera/" class="btn btn_google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a> </div> --> <a href="http://127.0.0.1:4000//posts" title="posts" class="posts-menu-icon"></a> <span class="posts-link-post">POSTS</span> <a title="project" class="projects-menu-icon"> <span></span> </a> <span class="projects-link-post">PROJECTS</span> <div class="inner-post"> <div class="date-highlight">27 Apr 2019</div> <ul class="tags"> <li><a href="http://127.0.0.1:4000//tags#machine learning">machine learning</a></li> <li><a href="http://127.0.0.1:4000//tags#deep learning">deep learning</a></li> <li><a href="http://127.0.0.1:4000//tags#hydroinformatics">hydroinformatics</a></li> <li><a href="http://127.0.0.1:4000//tags#data scientist">data scientist</a></li> </ul> <h1 id="rainfall-camera">Rainfall Camera</h1> <hr /> <figure style="width: 80%" class="align-center"> <img align="center" src="http://127.0.0.1:4000//images/Singapore.PNG" /> </figure> <h2 id="contents"><em>Contents</em></h2> <h3 id="introductionintroduction">1. <a href="#introduction">Introduction</a></h3> <h3 id="classifierclassifier">2. <a href="#classifier">Classifier</a></h3> <h3 id="normal-rainfall-processingnormal">3. <a href="#normal">Normal Rainfall Processing</a></h3> <h4 id="model-descriptiondescription">3.1 <a href="#description">Model Description</a></h4> <h4 id="model-efficiencyefficiency">3.2 <a href="#efficiency">Model Efficiency</a></h4> <h3 id="heavy-rainfall-processingheavy">4. <a href="#heavy">Heavy Rainfall Processing</a></h3> <h3 id="night-image-processingnight">5. <a href="#night">Night Image Processing</a></h3> <h3 id="validationvalidation">6. <a href="#validation">Validation</a></h3> <h3 id="referencereference">7. <a href="#reference">Reference</a></h3> <h3 id="miscmisc">8. <a href="#misc">Misc</a></h3> <h4 id="demodemo">8.1 <a href="#demo">Demo</a></h4> <h4 id="to-do-listtodo">8.2 <a href="#todo">To-do List</a></h4> <h4 id="updatesupdate">8.3 <a href="#update">Updates</a></h4> <h2 id="introductiona-nameintroductiona"><em>Introduction</em><a name="introduction"></a></h2> <figure style="width: 40%" class="align-center"> <img src="http://127.0.0.1:4000//images/Flowchart.png" /> <figcaption>Fig.1 Flow Chart of Rainfall Camera</figcaption> </figure> <p><br /></p> <h2 id="classifiera-nameclassifiera"><em>Classifier</em><a name="classifier"></a></h2> <ol> <li>Model Description:</li> </ol> <blockquote> <p>The model built for classifying rainfall images is <a href="https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72">SVM</a>, which in general, seperate datapoints with hyperplanes. The reason why we build a relatively light model is for the sake of computational time. The simplest and robust way is what we seek for.</p> </blockquote> <ol> <li>Data Acquisition:</li> </ol> <blockquote> <p>To build such machine-learning model, we still need information to train it. With four categories we want to specify, 100 images inside each category are selected from the streaming videos. Image size to train is confined with (300,300).</p> </blockquote> <ol> <li>Information to support:</li> </ol> <blockquote> <p>With data, how can we translate image into useful information that we can feed into SVM? By considering the characteristics during night, rainy days, heavy rainfall and sunny days, I came up with five informative descriptions: contrast, brightness, sharpness, hue and saturation.</p> </blockquote> <ol> <li>Return:</li> </ol> <blockquote> <p>After implementing this classifier, we are able to get a assigned probability of each category for single image.</p> </blockquote> <h2 id="normal-rainfall-processinga-namenormala"><em>Normal Rainfall Processing</em><a name="normal"></a></h2> <h3 id="model-descriptiona-namedescriptiona"><em>Model Description</em><a name="description"></a></h3> <p>Follow the pipeline, we emphisize on how to extract the rainfall intensity. In this method we describe, we feed the classified rainy image denoted as R into 4 times pretrained recurrent neuron network to get the original de-rained image O. By simple substracting and binary thresholding, we are able to get rainfall streaks S for analysis. But according to experiment, some images still quite messy under the condition that the moving trees and some hight pixel values give a false signal. In order to safeguard the following calculation process, we need to provide more accurate rainfall streaks. By achieving this, we decompose S with PCA and analyse the morphology of rain streaks etc. the shape of rain streak, the width of the rain streak, the orientation of the rain streak. With provided constraints, the output purified image will eventually put into Allamano algorithm.</p> <p align="center"> <img height="50%" src="http://127.0.0.1:4000//images/normal_pipeline.png" /><br /> Fig.2 Pipeline of normal rainfall process </p> <p><strong>1. RNN</strong></p> <p align="center"> <img align="center" src="http://127.0.0.1:4000//images/RNN.PNG" /><br /> Fig.3 Overview of RNN model (Progressive Image Deraining Networks: A Better and Simpler Baseline) </p> <p><br /></p> <p><strong>2. Allamano Algorithm</strong></p> <p align="center"> <img src="https://raw.githubusercontent.com/chrimerss/RainProperty/master/Rainstreak.png" align="center" /><br /> Fig.4 Example of delineated rain streaks </p> <p><br /></p> <blockquote> <p>Allamano Algorithm is used for evaluating the rainfall intensity, the philosophi behind is control volume approach to count rain drops inside the defined bounding box, and calculate rainfall terminal velocity etc.</p> </blockquote> <p>an event on 2018.12.08 demonstrates the accuracy of this series of images.</p> <p align="center"> <img src="http://127.0.0.1:4000//images/20181212-demo.gif" /><br /> Fig.5 Event 2018.12.12 at H2i, Singapore </p> <h3 id="model-efficiencya-nameefficiencya"><em>Model Efficiency</em><a name="efficiency"></a></h3> <table> <thead> <tr> <th>Object</th> <th>Total Elapsed Time</th> <th>Average Elapsed Time per Image</th> <th>GPU_CPU</th> <th>Cores or Threads</th> </tr> </thead> <tbody> <tr> <td>2018.04.01</td> <td>1.12 hours</td> <td>1.30 seconds</td> <td>GPU</td> <td>8</td> </tr> <tr> <td>2018.12.08</td> <td>0.45 hours</td> <td>0.91 seconds</td> <td>GPU</td> <td>8</td> </tr> <tr> <td>2018.12.11</td> <td>0.71 hours</td> <td>1.03 seconds</td> <td>GPU</td> <td>8</td> </tr> <tr> <td>2018.12.12</td> <td>1.15 hours</td> <td>1.34 seconds</td> <td>GPU</td> <td>8</td> </tr> </tbody> </table> <h2 id="heavy-rainfall-processinga-nameheavya"><em>Heavy Rainfall Processing</em><a name="heavy"></a></h2> <div class="highlighter-rouge"><pre class="highlight"><code>So far, we are limited by the data available to supervise a model towards the "correct" path
will add once more data can be aquired
</code></pre></div> <h2 id="night-image-processinga-namenighta"><em>Night Image Processing</em><a name="night"></a></h2> <p>Some modern techniques goes here.</p> <h2 id="validationa-namevalidationa"><em>Validation</em><a name="validation"></a></h2> <p>We have three data sources to validate our camera accuracy, first are three radars located in the northern, eastern and western part of Singapore. Another sources are 83 rain gauges densely distributed in Singapore. To bear in mind, the nearest rain gauges is still 300 meters away, and radar averages surroundings by 700 meters by 700 meters median filter. These two biases indicate that none of the two are convincible, and no updates will be given before some in-site measurement is placed right with camera.</p> <p align="center"> <img src="http://127.0.0.1:4000//images/2018-1211-ts.png" height="60%" /><br /> Fig.6 Time Series Plot of One Event<br /> <img src="http://127.0.0.1:4000//images/2018-1211-cts.png" height="60%" /><br /> Fig.7 Cumulative Time Series Plot of One Event<br /> </p> <h2 id="referencea-namereferencea"><em>Reference</em><a name="reference"></a></h2> <p>R. Dongwei, Z. Wangmeng etc. (2019) <em>Progressive Image Deraining Networks: A Better and Simpler Baseline</em> R. Martin and M. Frank (2008.) <em>Classification of Weather Situations on Single Color Images</em> P. Allamano, A. Croci, and F. Laio1 (2015) <em>Toward the camera rain gauge</em></p> <h2 id="miscellaneousa-namemisca"><em>Miscellaneous</em><a name="misc"></a></h2> <h3 id="demoa-namedemoa"><em>Demo</em><a name="demo"></a></h3> <p>In the api folder, there is a simple demo classifying an image and extract the rainfall intensity with built <a href="http://flask.pocoo.org/">Flask</a> backend</p> <div class="highlighter-rouge"><pre class="highlight"><code><span class="n">python</span> <span class="n">api</span><span class="o">.</span><span class="n">py</span>
</code></pre></div> <p>a local server should be set up at port 8000, in your browser, enter in localhost:8000, then the interface will pop up as</p> <p align="center"> <img src="http://127.0.0.1:4000//images/capture_of_localhost.PNG" align="center" /><br /> Fig.5 Snapshot of the local server </p> <p><br /></p> <h3 id="to-do-lista-nametodoa"><em>To-do list</em><a name="todo"></a></h3> <ul> <li>[x] build dask task manager</li> <li>[x] add classifier</li> <li>[x] Flask server</li> <li>[ ] Host on cloud</li> <li>[ ] add regression model/convert to RGB image</li> <li>[ ] night image processing</li> <li>[ ] GUI</li> <li>[x] add visualization</li> <li>[ ] add computational time table</li> <li>[ ] GPU version(convert all dask array to torch array and hard code torch version SVM)</li> <li>[ ] Validation with radar and rain gauges</li> </ul> <h3 id="updatesa-nameupdatea"><em>Updates</em><a name="update"></a></h3> <div class="highlighter-rouge"><pre class="highlight"><code>2019.4.24 Optimize codes to speed up.
2019.4.22 Flask local server to classify image
2019.4.19 add visualization.py
2019.4.18 optimized code and retrained model
2019.4.17 dask implementation
2019.4.15 trained a classifier model
</code></pre></div> <br> <p align=center> <a href="https://twitter.com/intent/tweet?text=http://127.0.0.1:4000//post-camera/" class="btn btn_twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> <a href="https://www.facebook.com/sharer/sharer.php?u=http://127.0.0.1:4000//post-camera/" class="btn btn_facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a> <a href="https://plus.google.com/share?url=http://127.0.0.1:4000//post-camera/" class="btn btn_google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a> </p> <nav class="pagination"> <a href="#" class="pagination_pager disabled">previous</a> <a href="http://127.0.0.1:4000//post-radar/" class="pagination_pager" title="Radar Project in Singapore ">next</a> </nav> </div> </div> <!-- JS --> <script src="http://127.0.0.1:4000//assets/js/main.min.js"></script> <div class="overlay"> <ul class="projects-menu"> <li style="background:url(http://127.0.0.1:4000//images/camera.jpg) center center no-repeat;"> <a href="https://chrimerss.github.io//post-camera/" target="_blank" rel="nofollow external"> <span> Rainfall Camera </span> </a> </li> <li style="background:url(http://127.0.0.1:4000//images/radarproject.png) center center no-repeat;"> <a href="http://www.h2i.sg/radar-rainfall-monitoring-and-nowcasting-system-for-urban-flood-management-in-singapore" target="_blank" rel="nofollow external"> <span> Rainfall Radar </span> </a> </li> <li style="background:url(http://127.0.0.1:4000//images/TC/domain.png) center center no-repeat;"> <a href="https://chrimerss.github.io//post-TC/" target="_blank" rel="nofollow external"> <span> Triple Collocation </span> </a> </li> <li style="background:url(http://127.0.0.1:4000//images/AMSU/crosstrack_scanners.gif) center center no-repeat;"> <a href="https://chrimerss.github.io//post-AMSU/" target="_blank" rel="nofollow external"> <span> Satellite Precipitation </span> </a> </li> <li style="background:url(http://127.0.0.1:4000//images/flood/animation_resize.gif) center center no-repeat;"> <a href="" class="inactive" target="_blank" rel="nofollow external"> <span> Flood simulation <br><em>in progress</em> </span> </a> </li> </ul> </div> </body> </html>
