<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.1.2">Jekyll</generator><link href="http://127.0.0.1:4000//feed.xml" rel="self" type="application/atom+xml" /><link href="http://127.0.0.1:4000//" rel="alternate" type="text/html" /><updated>2019-04-27T23:56:21+08:00</updated><id>http://127.0.0.1:4000//</id><title>(Allen) Zhi Li</title><subtitle>Data Scientist @ Hydroinformatics Institute</subtitle><entry><title>Rainfall Camera</title><link href="http://127.0.0.1:4000//post/" rel="alternate" type="text/html" title="Rainfall Camera" /><published>2019-04-27T00:00:00+08:00</published><updated>2019-04-27T00:00:00+08:00</updated><id>http://127.0.0.1:4000//post</id><content type="html" xml:base="http://127.0.0.1:4000//post/">&lt;h1 id=&quot;rainfall-camera&quot;&gt;Rainfall Camera&lt;/h1&gt;
&lt;hr /&gt;

&lt;figure&gt;
&lt;img align=&quot;right&quot; src=&quot;images/h2i_header.jpg&quot; width=&quot;40%&quot; /&gt;
&lt;img align=&quot;center&quot; src=&quot;images/Singapore.PNG&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;contents&quot;&gt;&lt;em&gt;Contents&lt;/em&gt;&lt;/h2&gt;

&lt;h3 id=&quot;introductionintroduction&quot;&gt;1. &lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;### 2. &lt;a href=&quot;#classifier&quot;&gt;Classifier&lt;/a&gt;
### 3. &lt;a href=&quot;#normal&quot;&gt;Normal Rainfall Processing&lt;/a&gt;
#### 3.1 &lt;a href=&quot;#description&quot;&gt;Model Description&lt;/a&gt;
#### 3.2 &lt;a href=&quot;#efficiency&quot;&gt;Model Efficiency&lt;/a&gt;
### 4. &lt;a href=&quot;#heavy&quot;&gt;Heavy Rainfall Processing&lt;/a&gt;
### 5. &lt;a href=&quot;#night&quot;&gt;Night Image Processing&lt;/a&gt;
### 6. &lt;a href=&quot;#validation&quot;&gt;Validation&lt;/a&gt;
### 7. &lt;a href=&quot;#reference&quot;&gt;Reference&lt;/a&gt;
### 8. &lt;a href=&quot;#misc&quot;&gt;Misc&lt;/a&gt;
#### 8.1 &lt;a href=&quot;#demo&quot;&gt;Demo&lt;/a&gt;
#### 8.2 &lt;a href=&quot;#todo&quot;&gt;To-do List&lt;/a&gt;
#### 8.3 &lt;a href=&quot;#update&quot;&gt;Updates&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;introductiona-nameintroductiona&quot;&gt;&lt;em&gt;Introduction&lt;/em&gt;&lt;a name=&quot;introduction&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img height=&quot;50%&quot; width=&quot;50%&quot; src=&quot;images/Flowchart.png&quot; /&gt;&lt;br /&gt;
   Fig.1 Flow Chart of Rainfall Camera
&lt;/p&gt;

&lt;h2 id=&quot;classifiera-nameclassifiera&quot;&gt;&lt;em&gt;Classifier&lt;/em&gt;&lt;a name=&quot;classifier&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Model Description:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;The model built for classifying rainfall images is &lt;a href=&quot;https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72&quot;&gt;SVM&lt;/a&gt;, which in general, seperate datapoints with hyperplanes. The reason why we build a relatively light model is for the sake of computational time. The simplest and robust way is what we seek for.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;Data Acquisition:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;To build such machine-learning model, we still need information to train it. With four categories we want to specify, 100 images inside each category are selected from the streaming videos. Image size to train is confined with (300,300).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;Information to support:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;With data, how can we translate image into useful information that we can feed into SVM? By considering the characteristics during night, rainy days, heavy rainfall and sunny days, I came up with five informative descriptions: contrast, brightness, sharpness, hue and saturation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;Return:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;After implementing this classifier, we are able to get a assigned probability of each category for single image.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;normal-rainfall-processinga-namenormala&quot;&gt;&lt;em&gt;Normal Rainfall Processing&lt;/em&gt;&lt;a name=&quot;normal&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;model-descriptiona-namedescriptiona&quot;&gt;&lt;em&gt;Model Description&lt;/em&gt;&lt;a name=&quot;description&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Follow the pipeline, we emphisize on how to extract the rainfall intensity. In this method we describe, we feed the classified rainy image denoted as R into 4 times pretrained recurrent neuron network to get the original de-rained image O. By simple substracting and binary thresholding, we are able to get rainfall streaks S for analysis. But according to experiment, some images still quite messy under the condition that the moving trees and some hight pixel values give a false signal. In order to safeguard the following calculation process, we need to provide more accurate rainfall streaks. By achieving this, we decompose S with PCA and analyse the morphology of rain streaks etc. the shape of rain streak, the width of the rain streak, the orientation of the rain streak. With provided constraints, the output purified image will eventually put into Allamano algorithm.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img height=&quot;50%&quot; src=&quot;images/normal_pipeline.png&quot; /&gt;&lt;br /&gt;
    Fig.2 Pipeline of normal rainfall process
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. RNN&lt;/strong&gt;&amp;lt;hr style=&quot;height:10px; visibility:hidden&quot;&amp;gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;img align=&quot;center&quot; src=&quot;images/RNN.PNG&quot; /&gt;&lt;br /&gt;
   Fig.3 Overview of RNN model (Progressive Image Deraining Networks: A Better and Simpler Baseline)
   &lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Allamano Algorithm&lt;/strong&gt;&amp;lt;hr style=&quot;height:10px; visibility:hidden&quot;&amp;gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;img src=&quot;https://raw.githubusercontent.com/chrimerss/RainProperty/master/Rainstreak.png&quot; align=&quot;center&quot; /&gt;&lt;br /&gt;
   Fig.4 Example of delineated rain streaks
   &lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Allamano Algorithm is used for evaluating the rainfall intensity, the philosophi behind is control volume approach to count rain drops inside the defined bounding box, and calculate rainfall terminal velocity etc.&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;an event on 2018.12.08 demonstrates the accuracy of this series of images.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;images/20181212-demo.gif&quot; /&gt;&lt;br /&gt;
    Fig.5 Event 2018.12.12 at H2i, Singapore
   &lt;/p&gt;

&lt;h3 id=&quot;model-efficiencya-nameefficiencya&quot;&gt;&lt;em&gt;Model Efficiency&lt;/em&gt;&lt;a name=&quot;efficiency&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Object&lt;/th&gt;
      &lt;th&gt;Total Elapsed Time&lt;/th&gt;
      &lt;th&gt;Average Elapsed Time per Image&lt;/th&gt;
      &lt;th&gt;GPU_CPU&lt;/th&gt;
      &lt;th&gt;Cores or Threads&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;2018.04.01&lt;/td&gt;
      &lt;td&gt;1.12 hours&lt;/td&gt;
      &lt;td&gt;1.30 seconds&lt;/td&gt;
      &lt;td&gt;GPU&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2018.12.08&lt;/td&gt;
      &lt;td&gt;0.45 hours&lt;/td&gt;
      &lt;td&gt;0.91 seconds&lt;/td&gt;
      &lt;td&gt;GPU&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2018.12.11&lt;/td&gt;
      &lt;td&gt;0.71 hours&lt;/td&gt;
      &lt;td&gt;1.03 seconds&lt;/td&gt;
      &lt;td&gt;GPU&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2018.12.12&lt;/td&gt;
      &lt;td&gt;1.15 hours&lt;/td&gt;
      &lt;td&gt;1.34 seconds&lt;/td&gt;
      &lt;td&gt;GPU&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;heavy-rainfall-processinga-nameheavya&quot;&gt;&lt;em&gt;Heavy Rainfall Processing&lt;/em&gt;&lt;a name=&quot;heavy&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;So far, we are limited by the data available to supervise a model towards the &quot;correct&quot; path
will add once more data can be aquired
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;night-image-processinga-namenighta&quot;&gt;&lt;em&gt;Night Image Processing&lt;/em&gt;&lt;a name=&quot;night&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Some modern techniques goes here.&lt;/p&gt;

&lt;h2 id=&quot;validationa-namevalidationa&quot;&gt;&lt;em&gt;Validation&lt;/em&gt;&lt;a name=&quot;validation&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;We have three data sources to validate our camera accuracy, first are three radars located in the northern, eastern and western part of Singapore. Another sources are 83 rain gauges densely distributed in Singapore. To bear in mind, the nearest rain gauges is still 300 meters away, and radar averages surroundings by 700 meters by 700 meters median filter. These two biases indicate that none of the two are convincible, and no updates will be given before some in-site measurement is placed right with camera.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;img src=&quot;images/2018-1211-ts.png&quot; height=&quot;60%&quot; /&gt;&lt;br /&gt;
   Fig.6 Time Series Plot of One Event&lt;br /&gt;
   &lt;img src=&quot;images/2018-1211-cts.png&quot; height=&quot;60%&quot; /&gt;&lt;br /&gt;
   Fig.7 Cumulative Time Series Plot of One Event&lt;br /&gt;
   &lt;/p&gt;

&lt;h2 id=&quot;referencea-namereferencea&quot;&gt;&lt;em&gt;Reference&lt;/em&gt;&lt;a name=&quot;reference&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;R. Dongwei, Z. Wangmeng etc. (2019) &lt;em&gt;Progressive Image Deraining Networks: A Better and Simpler Baseline&lt;/em&gt;
R. Martin and M. Frank (2008.) &lt;em&gt;Classification of Weather Situations on Single Color Images&lt;/em&gt;
P. Allamano, A. Croci, and F. Laio1 (2015) &lt;em&gt;Toward the camera rain gauge&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;miscellaneousa-namemisca&quot;&gt;&lt;em&gt;Miscellaneous&lt;/em&gt;&lt;a name=&quot;misc&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;demoa-namedemoa&quot;&gt;&lt;em&gt;Demo&lt;/em&gt;&lt;a name=&quot;demo&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;In the api folder, there is a simple demo classifying an image and extract the rainfall intensity with built &lt;a href=&quot;http://flask.pocoo.org/&quot;&gt;Flask&lt;/a&gt; backend&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;python&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;api&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;a local server should be set up at port 8000, in your browser, enter in localhost:8000, then the interface will pop up as&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;img src=&quot;images/capture_of_localhost.PNG&quot; align=&quot;center&quot; /&gt;&lt;br /&gt;
   Fig.5 Snapshot of the local server
   &lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;to-do-lista-nametodoa&quot;&gt;&lt;em&gt;To-do list&lt;/em&gt;&lt;a name=&quot;todo&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;[x] build dask task manager&lt;/li&gt;
  &lt;li&gt;[x] add classifier&lt;/li&gt;
  &lt;li&gt;[x] Flask server&lt;/li&gt;
  &lt;li&gt;[ ] Host on cloud&lt;/li&gt;
  &lt;li&gt;[ ] add regression model/convert to RGB image&lt;/li&gt;
  &lt;li&gt;[ ] night image processing&lt;/li&gt;
  &lt;li&gt;[ ] GUI&lt;/li&gt;
  &lt;li&gt;[x] add visualization&lt;/li&gt;
  &lt;li&gt;[ ] add computational time table&lt;/li&gt;
  &lt;li&gt;[ ] GPU version(convert all dask array to torch array and hard code torch version SVM)&lt;/li&gt;
  &lt;li&gt;[ ] Validation with radar and rain gauges&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;updatesa-nameupdatea&quot;&gt;&lt;em&gt;Updates&lt;/em&gt;&lt;a name=&quot;update&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019.4.24 Optimize codes to speed up.
2019.4.22 Flask local server to classify image
2019.4.19 add visualization.py
2019.4.18 optimized code and retrained model
2019.4.17 dask implementation
2019.4.15 trained a classifier model
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;</content><category term="machine learning" /><category term="deep learning" /><category term="hydroinformatics" /><category term="data scientist" /><summary>Rainfall Camera







Contents

1. Introduction
### 2. Classifier
### 3. Normal Rainfall Processing
#### 3.1 Model Description
#### 3.2 Model Efficiency
### 4. Heavy Rainfall Processing
### 5. Night Image Processing
### 6. Validation
### 7. Reference
### 8. Misc
#### 8.1 Demo
#### 8.2 To-do List
#### 8.3 Updates

Introduction


  
   Fig.1 Flow Chart of Rainfall Camera


Classifier


  Model Description:



  The model built for classifying rainfall images is SVM, which in general, seperate datapoints with hyperplanes. The reason why we build a relatively light model is for the sake of computational time. The simplest and robust way is what we seek for.



  Data Acquisition:



  To build such machine-learning model, we still need information to train it. With four categories we want to specify, 100 images inside each category are selected from the streaming videos. Image size to train is confined with (300,300).



  Information to support:



  With data, how can we translate image into useful information that we can feed into SVM? By considering the characteristics during night, rainy days, heavy rainfall and sunny days, I came up with five informative descriptions: contrast, brightness, sharpness, hue and saturation.



  Return:



  After implementing this classifier, we are able to get a assigned probability of each category for single image.


Normal Rainfall Processing

Model Description

Follow the pipeline, we emphisize on how to extract the rainfall intensity. In this method we describe, we feed the classified rainy image denoted as R into 4 times pretrained recurrent neuron network to get the original de-rained image O. By simple substracting and binary thresholding, we are able to get rainfall streaks S for analysis. But according to experiment, some images still quite messy under the condition that the moving trees and some hight pixel values give a false signal. In order to safeguard the following calculation process, we need to provide more accurate rainfall streaks. By achieving this, we decompose S with PCA and analyse the morphology of rain streaks etc. the shape of rain streak, the width of the rain streak, the orientation of the rain streak. With provided constraints, the output purified image will eventually put into Allamano algorithm.


  
    Fig.2 Pipeline of normal rainfall process


1. RNN&amp;lt;hr style=&quot;height:10px; visibility:hidden&quot;&amp;gt;


   
   Fig.3 Overview of RNN model (Progressive Image Deraining Networks: A Better and Simpler Baseline)
   


2. Allamano Algorithm&amp;lt;hr style=&quot;height:10px; visibility:hidden&quot;&amp;gt;


   
   Fig.4 Example of delineated rain streaks
   




  Allamano Algorithm is used for evaluating the rainfall intensity, the philosophi behind is control volume approach to count rain drops inside the defined bounding box, and calculate rainfall terminal velocity etc.



an event on 2018.12.08 demonstrates the accuracy of this series of images.


    
    Fig.5 Event 2018.12.12 at H2i, Singapore
   

Model Efficiency


  
    
      Object
      Total Elapsed Time
      Average Elapsed Time per Image
      GPU_CPU
      Cores or Threads
    
  
  
    
      2018.04.01
      1.12 hours
      1.30 seconds
      GPU
      8
    
    
      2018.12.08
      0.45 hours
      0.91 seconds
      GPU
      8
    
    
      2018.12.11
      0.71 hours
      1.03 seconds
      GPU
      8
    
    
      2018.12.12
      1.15 hours
      1.34 seconds
      GPU
      8
    
  


Heavy Rainfall Processing

So far, we are limited by the data available to supervise a model towards the &quot;correct&quot; path
will add once more data can be aquired



Night Image Processing

Some modern techniques goes here.

Validation

We have three data sources to validate our camera accuracy, first are three radars located in the northern, eastern and western part of Singapore. Another sources are 83 rain gauges densely distributed in Singapore. To bear in mind, the nearest rain gauges is still 300 meters away, and radar averages surroundings by 700 meters by 700 meters median filter. These two biases indicate that none of the two are convincible, and no updates will be given before some in-site measurement is placed right with camera.


   
   Fig.6 Time Series Plot of One Event
   
   Fig.7 Cumulative Time Series Plot of One Event
   

Reference

R. Dongwei, Z. Wangmeng etc. (2019) Progressive Image Deraining Networks: A Better and Simpler Baseline
R. Martin and M. Frank (2008.) Classification of Weather Situations on Single Color Images
P. Allamano, A. Croci, and F. Laio1 (2015) Toward the camera rain gauge

Miscellaneous

Demo

In the api folder, there is a simple demo classifying an image and extract the rainfall intensity with built Flask backend

python api.py



a local server should be set up at port 8000, in your browser, enter in localhost:8000, then the interface will pop up as


   
   Fig.5 Snapshot of the local server
   



To-do list

  [x] build dask task manager
  [x] add classifier
  [x] Flask server
  [ ] Host on cloud
  [ ] add regression model/convert to RGB image
  [ ] night image processing
  [ ] GUI
  [x] add visualization
  [ ] add computational time table
  [ ] GPU version(convert all dask array to torch array and hard code torch version SVM)
  [ ] Validation with radar and rain gauges


Updates

2019.4.24 Optimize codes to speed up.
2019.4.22 Flask local server to classify image
2019.4.19 add visualization.py
2019.4.18 optimized code and retrained model
2019.4.17 dask implementation
2019.4.15 trained a classifier model</summary></entry></feed>
